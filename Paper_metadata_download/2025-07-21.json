[
  {
    "paper": {
      "id": "2507.10605",
      "authors": [
        {
          "_id": "687da15e2e8db0930be6f0aa",
          "name": "Fei Zhao",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0ab",
          "name": "Chonggang Lu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0ac",
          "name": "Yue Wang",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0ad",
          "name": "Zheyong Xie",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0ae",
          "name": "Ziyan Liu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0af",
          "name": "Haofu Qian",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b0",
          "name": "JianZhao Huang",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b1",
          "name": "Fangcheng Shi",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b2",
          "name": "Zijie Meng",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b3",
          "name": "Hongcheng Guo",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b4",
          "name": "Mingqian He",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b5",
          "name": "Xinze Lyu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b6",
          "name": "Yiming Lu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b7",
          "name": "Ziyang Xiang",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b8",
          "name": "Zheyu Ye",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0b9",
          "name": "Chengqiang Lu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0ba",
          "name": "Zhe Xu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0bb",
          "name": "Yi Wu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0bc",
          "name": "Yao Hu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0bd",
          "name": "Yan Gao",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0be",
          "name": "Jun Fan",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0bf",
          "name": "Xiaolong Jiang",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0c0",
          "name": "Weiting Liu",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0c1",
          "name": "Boyang Wang",
          "hidden": false
        },
        {
          "_id": "687da15e2e8db0930be6f0c2",
          "name": "Shaosheng Cao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-13T02:22:59.000Z",
      "submittedOnDailyAt": "2025-07-21T00:42:35.284Z",
      "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking\n  Services",
      "submittedOnDailyBy": {
        "_id": "65328aa39326d6da5ff19b52",
        "avatarUrl": "/avatars/5c3de984cd6eba69616bb608796865c5.svg",
        "isPro": false,
        "fullname": "Fei Zhao",
        "user": "Hiiamein",
        "type": "user"
      },
      "summary": "As a primary medium for modern information dissemination, social networking\nservices (SNS) have experienced rapid growth, which has proposed significant\nchallenges for platform content management and interaction quality improvement.\nRecently, the development of large language models (LLMs) has offered potential\nsolutions but existing studies focus on isolated tasks, which not only\nencounter diminishing benefit from the data scaling within individual scenarios\nbut also fail to flexibly adapt to diverse real-world context. To address these\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\nperformance bottleneck of single-task baselines and establish a comprehensive\nfoundation for the SNS. RedOne was developed through a three-stage training\nstrategy consisting of continue pretraining, supervised fine-tuning, and\npreference optimization, using a large-scale real-world dataset. Through\nextensive experiments, RedOne maintains strong general capabilities, and\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\nthrough online testing, RedOne reduced the exposure rate in harmful content\ndetection by 11.23% and improved the click page rate in post-view search by\n14.95% compared with single-tasks finetuned baseline models. These results\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\nexcellent generalization across various tasks and promising applicability in\nreal-world scenarios.",
      "upvotes": 2,
      "discussionId": "687da15f2e8db0930be6f0c3",
      "ai_summary": "RedOne, a domain-specific LLM, enhances performance across multiple SNS tasks through a three-stage training strategy, improving generalization and reducing harmful content exposure.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "domain-specific LLM",
        "continue pretraining",
        "supervised fine-tuning",
        "preference optimization",
        "SNS tasks",
        "bilingual evaluation benchmark",
        "harmful content detection",
        "click page rate",
        "post-view search"
      ]
    },
    "publishedAt": "2025-07-12T22:22:59.000Z",
    "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking\n  Services",
    "summary": "As a primary medium for modern information dissemination, social networking\nservices (SNS) have experienced rapid growth, which has proposed significant\nchallenges for platform content management and interaction quality improvement.\nRecently, the development of large language models (LLMs) has offered potential\nsolutions but existing studies focus on isolated tasks, which not only\nencounter diminishing benefit from the data scaling within individual scenarios\nbut also fail to flexibly adapt to diverse real-world context. To address these\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\nperformance bottleneck of single-task baselines and establish a comprehensive\nfoundation for the SNS. RedOne was developed through a three-stage training\nstrategy consisting of continue pretraining, supervised fine-tuning, and\npreference optimization, using a large-scale real-world dataset. Through\nextensive experiments, RedOne maintains strong general capabilities, and\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\nthrough online testing, RedOne reduced the exposure rate in harmful content\ndetection by 11.23% and improved the click page rate in post-view search by\n14.95% compared with single-tasks finetuned baseline models. These results\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\nexcellent generalization across various tasks and promising applicability in\nreal-world scenarios.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.10605.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65328aa39326d6da5ff19b52",
      "avatarUrl": "/avatars/5c3de984cd6eba69616bb608796865c5.svg",
      "fullname": "Fei Zhao",
      "name": "Hiiamein",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  }
]