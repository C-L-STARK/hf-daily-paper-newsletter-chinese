[
  {
    "paper": {
      "id": "2506.05984",
      "authors": [
        {
          "_id": "68463ee43ec10bdd8ab4da6f",
          "name": "Cheng-Han Chiang",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da70",
          "user": {
            "_id": "64dc191bc307ee5369fbcb04",
            "avatarUrl": "/avatars/5a8a0db63a187e85d4ae2fff93a838f0.svg",
            "isPro": false,
            "fullname": "Xiaofei Wang",
            "user": "xiaofei-wang",
            "type": "user"
          },
          "name": "Xiaofei Wang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-09T01:54:46.319Z",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da71",
          "name": "Chung-Ching Lin",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da72",
          "name": "Kevin Lin",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da73",
          "name": "Linjie Li",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da74",
          "name": "Radu Kopetz",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da75",
          "name": "Yao Qian",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da76",
          "name": "Zhendong Wang",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da77",
          "name": "Zhengyuan Yang",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da78",
          "name": "Hung-yi Lee",
          "hidden": false
        },
        {
          "_id": "68463ee43ec10bdd8ab4da79",
          "name": "Lijuan Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-06T11:05:48.000Z",
      "submittedOnDailyAt": "2025-06-09T00:28:11.753Z",
      "title": "Audio-Aware Large Language Models as Judges for Speaking Styles",
      "submittedOnDailyBy": {
        "_id": "622326ae0129f2097d69a3e2",
        "avatarUrl": "/avatars/7665223e3fc8b820ce001e6003daf4d2.svg",
        "isPro": false,
        "fullname": "Cheng-Han Chiang",
        "user": "dcml0714",
        "type": "user"
      },
      "summary": "Audio-aware large language models (ALLMs) can understand the textual and\nnon-textual information in the audio input. In this paper, we explore using\nALLMs as an automatic judge to assess the speaking styles of speeches. We use\nALLM judges to evaluate the speeches generated by SLMs on two tasks: voice\nstyle instruction following and role-playing. The speaking style we consider\nincludes emotion, volume, speaking pace, word emphasis, pitch control, and\nnon-verbal elements. We use four spoken language models (SLMs) to complete the\ntwo tasks and use humans and ALLMs to judge the SLMs' responses. We compare two\nALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and\nshow that the agreement between Gemini and human judges is comparable to the\nagreement between human evaluators. These promising results show that ALLMs can\nbe used as a judge to evaluate SLMs. Our results also reveal that current SLMs,\neven GPT-4o-audio, still have room for improvement in controlling the speaking\nstyle and generating natural dialogues.",
      "upvotes": 3,
      "discussionId": "68463ee43ec10bdd8ab4da7a",
      "ai_summary": "Audio-aware large language models can assess speaking styles in audio inputs, demonstrating performance comparable to human judges in evaluating synthesized speech along dimensions like emotion, volume, and pitch.",
      "ai_keywords": [
        "audio-aware large language models",
        "ALLMs",
        "speaking styles",
        "SLMs",
        "voice style instruction",
        "role-playing",
        "emotion",
        "volume",
        "speaking pace",
        "word emphasis",
        "pitch control",
        "non-verbal elements",
        "GPT-4o-audio",
        "Gemini-2.5-pro",
        "human evaluation",
        "agreement",
        "speaking style control",
        "natural dialogues"
      ]
    },
    "publishedAt": "2025-06-06T07:05:48.000Z",
    "title": "Audio-Aware Large Language Models as Judges for Speaking Styles",
    "summary": "Audio-aware large language models (ALLMs) can understand the textual and\nnon-textual information in the audio input. In this paper, we explore using\nALLMs as an automatic judge to assess the speaking styles of speeches. We use\nALLM judges to evaluate the speeches generated by SLMs on two tasks: voice\nstyle instruction following and role-playing. The speaking style we consider\nincludes emotion, volume, speaking pace, word emphasis, pitch control, and\nnon-verbal elements. We use four spoken language models (SLMs) to complete the\ntwo tasks and use humans and ALLMs to judge the SLMs' responses. We compare two\nALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and\nshow that the agreement between Gemini and human judges is comparable to the\nagreement between human evaluators. These promising results show that ALLMs can\nbe used as a judge to evaluate SLMs. Our results also reveal that current SLMs,\neven GPT-4o-audio, still have room for improvement in controlling the speaking\nstyle and generating natural dialogues.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.05984.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "622326ae0129f2097d69a3e2",
      "avatarUrl": "/avatars/7665223e3fc8b820ce001e6003daf4d2.svg",
      "fullname": "Cheng-Han Chiang",
      "name": "dcml0714",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  }
]