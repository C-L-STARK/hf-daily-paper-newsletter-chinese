[
  {
    "paper": {
      "id": "2507.02813",
      "authors": [
        {
          "_id": "686735e69db35afc9c304ce1",
          "name": "Fangfu Liu",
          "hidden": false
        },
        {
          "_id": "686735e69db35afc9c304ce2",
          "name": "Hao Li",
          "hidden": false
        },
        {
          "_id": "686735e69db35afc9c304ce3",
          "name": "Jiawei Chi",
          "hidden": false
        },
        {
          "_id": "686735e69db35afc9c304ce4",
          "name": "Hanyang Wang",
          "hidden": false
        },
        {
          "_id": "686735e69db35afc9c304ce5",
          "name": "Minghui Yang",
          "hidden": false
        },
        {
          "_id": "686735e69db35afc9c304ce6",
          "name": "Fudong Wang",
          "hidden": false
        },
        {
          "_id": "686735e69db35afc9c304ce7",
          "name": "Yueqi Duan",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6505a02f9310ce8c400edc63/GMjqJ0RyCYifjpsev_YPY.mp4"
      ],
      "publishedAt": "2025-07-03T17:21:23.000Z",
      "submittedOnDailyAt": "2025-07-04T00:35:47.996Z",
      "title": "LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with\n  TriMap Video Diffusion",
      "submittedOnDailyBy": {
        "_id": "6505a02f9310ce8c400edc63",
        "avatarUrl": "/avatars/bbf781594fc8c812316711aa8e2797aa.svg",
        "isPro": false,
        "fullname": "Fangfu Liu",
        "user": "Liuff23",
        "type": "user"
      },
      "summary": "Recovering 3D structures with open-vocabulary scene understanding from 2D\nimages is a fundamental but daunting task. Recent developments have achieved\nthis by performing per-scene optimization with embedded language information.\nHowever, they heavily rely on the calibrated dense-view reconstruction\nparadigm, thereby suffering from severe rendering artifacts and implausible\nsemantic synthesis when limited views are available. In this paper, we\nintroduce a novel generative framework, coined LangScene-X, to unify and\ngenerate 3D consistent multi-modality information for reconstruction and\nunderstanding. Powered by the generative capability of creating more consistent\nnovel observations, we can build generalizable 3D language-embedded scenes from\nonly sparse views. Specifically, we first train a TriMap video diffusion model\nthat can generate appearance (RGBs), geometry (normals), and semantics\n(segmentation maps) from sparse inputs through progressive knowledge\nintegration. Furthermore, we propose a Language Quantized Compressor (LQC),\ntrained on large-scale image datasets, to efficiently encode language\nembeddings, enabling cross-scene generalization without per-scene retraining.\nFinally, we reconstruct the language surface fields by aligning language\ninformation onto the surface of 3D scenes, enabling open-ended language\nqueries. Extensive experiments on real-world data demonstrate the superiority\nof our LangScene-X over state-of-the-art methods in terms of quality and\ngeneralizability. Project Page: https://liuff19.github.io/LangScene-X.",
      "upvotes": 16,
      "discussionId": "686735e69db35afc9c304ce8",
      "projectPage": "https://liuff19.github.io/LangScene-X/",
      "githubRepo": "https://github.com/liuff19/LangScene-X",
      "githubStars": 15
    },
    "publishedAt": "2025-07-03T13:21:23.000Z",
    "title": "LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with\n  TriMap Video Diffusion",
    "summary": "Recovering 3D structures with open-vocabulary scene understanding from 2D\nimages is a fundamental but daunting task. Recent developments have achieved\nthis by performing per-scene optimization with embedded language information.\nHowever, they heavily rely on the calibrated dense-view reconstruction\nparadigm, thereby suffering from severe rendering artifacts and implausible\nsemantic synthesis when limited views are available. In this paper, we\nintroduce a novel generative framework, coined LangScene-X, to unify and\ngenerate 3D consistent multi-modality information for reconstruction and\nunderstanding. Powered by the generative capability of creating more consistent\nnovel observations, we can build generalizable 3D language-embedded scenes from\nonly sparse views. Specifically, we first train a TriMap video diffusion model\nthat can generate appearance (RGBs), geometry (normals), and semantics\n(segmentation maps) from sparse inputs through progressive knowledge\nintegration. Furthermore, we propose a Language Quantized Compressor (LQC),\ntrained on large-scale image datasets, to efficiently encode language\nembeddings, enabling cross-scene generalization without per-scene retraining.\nFinally, we reconstruct the language surface fields by aligning language\ninformation onto the surface of 3D scenes, enabling open-ended language\nqueries. Extensive experiments on real-world data demonstrate the superiority\nof our LangScene-X over state-of-the-art methods in terms of quality and\ngeneralizability. Project Page: https://liuff19.github.io/LangScene-X.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6505a02f9310ce8c400edc63/GMjqJ0RyCYifjpsev_YPY.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.02813.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6505a02f9310ce8c400edc63",
      "avatarUrl": "/avatars/bbf781594fc8c812316711aa8e2797aa.svg",
      "fullname": "Fangfu Liu",
      "name": "Liuff23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.01352",
      "authors": [
        {
          "_id": "6865cdc28c83dab5f72d1e18",
          "name": "Chris Yuhao Liu",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e19",
          "user": {
            "_id": "6621efe1a6eec3ad03e38759",
            "avatarUrl": "/avatars/c35acce69f244ec0833dffd53eedf6a3.svg",
            "isPro": false,
            "fullname": "Liang Zeng",
            "user": "zengliangcs",
            "type": "user"
          },
          "name": "Liang Zeng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-07-03T16:19:08.221Z",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e1a",
          "name": "Yuzhen Xiao",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e1b",
          "name": "Jujie He",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e1c",
          "name": "Jiacai Liu",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e1d",
          "name": "Chaojie Wang",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e1e",
          "name": "Rui Yan",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e1f",
          "name": "Wei Shen",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e20",
          "name": "Fuxiang Zhang",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e21",
          "name": "Jiacheng Xu",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e22",
          "name": "Yang Liu",
          "hidden": false
        },
        {
          "_id": "6865cdc28c83dab5f72d1e23",
          "name": "Yahui Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-02T04:40:29.000Z",
      "submittedOnDailyAt": "2025-07-04T00:12:17.371Z",
      "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
      "submittedOnDailyBy": {
        "_id": "658229ef5f6d83438257fce5",
        "avatarUrl": "/avatars/b4417de9a338e95dc69cc547a46348e8.svg",
        "isPro": false,
        "fullname": "Chris (Yuhao) Liu",
        "user": "chrisliu298",
        "type": "user"
      },
      "summary": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.",
      "upvotes": 9,
      "discussionId": "6865cdc28c83dab5f72d1e24",
      "githubRepo": "https://github.com/SkyworkAI/Skywork-Reward-V2",
      "githubStars": 4
    },
    "publishedAt": "2025-07-02T00:40:29.000Z",
    "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
    "summary": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.01352.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "658229ef5f6d83438257fce5",
      "avatarUrl": "/avatars/b4417de9a338e95dc69cc547a46348e8.svg",
      "fullname": "Chris (Yuhao) Liu",
      "name": "chrisliu298",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2507.02592",
      "authors": [
        {
          "_id": "686732329db35afc9c304cb4",
          "name": "Kuan Li",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cb5",
          "name": "Zhongwang Zhang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cb6",
          "name": "Huifeng Yin",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cb7",
          "name": "Liwen Zhang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cb8",
          "name": "Litu Ou",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cb9",
          "name": "Jialong Wu",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cba",
          "name": "Wenbiao Yin",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cbb",
          "name": "Baixuan Li",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cbc",
          "name": "Zhengwei Tao",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cbd",
          "name": "Xinyu Wang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cbe",
          "name": "Weizhou Shen",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cbf",
          "name": "Junkai Zhang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc0",
          "name": "Dingchu Zhang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc1",
          "name": "Xixi Wu",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc2",
          "name": "Yong Jiang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc3",
          "name": "Ming Yan",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc4",
          "name": "Pengjun Xie",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc5",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "686732329db35afc9c304cc6",
          "name": "Jingren Zhou",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/622f2feea32d46b4be9ed8c4/9sUyYbIYfR5wDQMMft1io.png",
        "https://cdn-uploads.huggingface.co/production/uploads/622f2feea32d46b4be9ed8c4/FLz6T05o_NbbQKrOQyTuL.png"
      ],
      "publishedAt": "2025-07-03T12:59:07.000Z",
      "submittedOnDailyAt": "2025-07-04T00:20:59.450Z",
      "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
      "submittedOnDailyBy": {
        "_id": "622f2feea32d46b4be9ed8c4",
        "avatarUrl": "/avatars/ba25eb941a7c9a414b7fd4818adfa26b.svg",
        "isPro": false,
        "fullname": "Litu Ou",
        "user": "learn3r",
        "type": "user"
      },
      "summary": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all opensource agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
      "upvotes": 4,
      "discussionId": "686732339db35afc9c304cc7"
    },
    "publishedAt": "2025-07-03T08:59:07.000Z",
    "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
    "summary": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all opensource agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/622f2feea32d46b4be9ed8c4/9sUyYbIYfR5wDQMMft1io.png",
      "https://cdn-uploads.huggingface.co/production/uploads/622f2feea32d46b4be9ed8c4/FLz6T05o_NbbQKrOQyTuL.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.02592.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "622f2feea32d46b4be9ed8c4",
      "avatarUrl": "/avatars/ba25eb941a7c9a414b7fd4818adfa26b.svg",
      "fullname": "Litu Ou",
      "name": "learn3r",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.02652",
      "authors": [
        {
          "_id": "6867282b9db35afc9c304c83",
          "name": "Jiajie Jin",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c84",
          "name": "Xiaoxi Li",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c85",
          "name": "Guanting Dong",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c86",
          "name": "Yuyao Zhang",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c87",
          "name": "Yutao Zhu",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c88",
          "name": "Yang Zhao",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c89",
          "name": "Hongjin Qian",
          "hidden": false
        },
        {
          "_id": "6867282b9db35afc9c304c8a",
          "name": "Zhicheng Dou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-03T14:18:08.000Z",
      "submittedOnDailyAt": "2025-07-04T00:07:46.543Z",
      "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for\n  Deep Search",
      "submittedOnDailyBy": {
        "_id": "6695f14df0ffd8e3a379ad61",
        "avatarUrl": "/avatars/5ebb7e55ee9c2d93850b279f440675b0.svg",
        "isPro": false,
        "fullname": "Jiajie Jin",
        "user": "jinjiajie",
        "type": "user"
      },
      "summary": "Complex information needs in real-world search scenarios demand deep\nreasoning and knowledge synthesis across diverse sources, which traditional\nretrieval-augmented generation (RAG) pipelines struggle to address effectively.\nCurrent reasoning-based approaches suffer from a fundamental limitation: they\nuse a single model to handle both high-level planning and detailed execution,\nleading to inefficient reasoning and limited scalability. In this paper, we\nintroduce HiRA, a hierarchical framework that separates strategic planning from\nspecialized execution. Our approach decomposes complex search tasks into\nfocused subtasks, assigns each subtask to domain-specific agents equipped with\nexternal tools and reasoning capabilities, and coordinates the results through\na structured integration mechanism. This separation prevents execution details\nfrom disrupting high-level reasoning while enabling the system to leverage\nspecialized expertise for different types of information processing.\nExperiments on four complex, cross-modal deep search benchmarks demonstrate\nthat HiRA significantly outperforms state-of-the-art RAG and agent-based\nsystems. Our results show improvements in both answer quality and system\nefficiency, highlighting the effectiveness of decoupled planning and execution\nfor multi-step information seeking tasks. Our code is available at\nhttps://github.com/ignorejjj/HiRA.",
      "upvotes": 3,
      "discussionId": "6867282c9db35afc9c304c8b"
    },
    "publishedAt": "2025-07-03T10:18:08.000Z",
    "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for\n  Deep Search",
    "summary": "Complex information needs in real-world search scenarios demand deep\nreasoning and knowledge synthesis across diverse sources, which traditional\nretrieval-augmented generation (RAG) pipelines struggle to address effectively.\nCurrent reasoning-based approaches suffer from a fundamental limitation: they\nuse a single model to handle both high-level planning and detailed execution,\nleading to inefficient reasoning and limited scalability. In this paper, we\nintroduce HiRA, a hierarchical framework that separates strategic planning from\nspecialized execution. Our approach decomposes complex search tasks into\nfocused subtasks, assigns each subtask to domain-specific agents equipped with\nexternal tools and reasoning capabilities, and coordinates the results through\na structured integration mechanism. This separation prevents execution details\nfrom disrupting high-level reasoning while enabling the system to leverage\nspecialized expertise for different types of information processing.\nExperiments on four complex, cross-modal deep search benchmarks demonstrate\nthat HiRA significantly outperforms state-of-the-art RAG and agent-based\nsystems. Our results show improvements in both answer quality and system\nefficiency, highlighting the effectiveness of decoupled planning and execution\nfor multi-step information seeking tasks. Our code is available at\nhttps://github.com/ignorejjj/HiRA.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.02652.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6695f14df0ffd8e3a379ad61",
      "avatarUrl": "/avatars/5ebb7e55ee9c2d93850b279f440675b0.svg",
      "fullname": "Jiajie Jin",
      "name": "jinjiajie",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.02754",
      "authors": [
        {
          "_id": "686732e19db35afc9c304cc9",
          "name": "Aurko Roy",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304cca",
          "name": "Timothy Chou",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304ccb",
          "name": "Sai Surya Duvvuri",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304ccc",
          "name": "Sijia Chen",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304ccd",
          "name": "Jiecao Yu",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304cce",
          "name": "Xiaodong Wang",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304ccf",
          "name": "Manzil Zaheer",
          "hidden": false
        },
        {
          "_id": "686732e19db35afc9c304cd0",
          "name": "Rohan Anil",
          "hidden": false
        }
      ],
      "publishedAt": "2025-07-03T16:16:34.000Z",
      "submittedOnDailyAt": "2025-07-04T00:19:14.552Z",
      "title": "Fast and Simplex: 2-Simplicial Attention in Triton",
      "submittedOnDailyBy": {
        "_id": "651e96991b97c9f33d26bde6",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
        "isPro": false,
        "fullname": "Elie Bakouch",
        "user": "eliebak",
        "type": "user"
      },
      "summary": "Recent work has shown that training loss scales as a power law with both\nmodel size and the number of tokens, and that achieving compute-optimal models\nrequires scaling model size and token count together. However, these scaling\nlaws assume an infinite supply of data and apply primarily in compute-bound\nsettings. As modern large language models increasingly rely on massive\ninternet-scale datasets, the assumption that they are compute-bound is becoming\nless valid. This shift highlights the need for architectures that prioritize\ntoken efficiency.\n  In this work, we investigate the use of the 2-simplicial Transformer, an\narchitecture that generalizes standard dot-product attention to trilinear\nfunctions through an efficient Triton kernel implementation. We demonstrate\nthat the 2-simplicial Transformer achieves better token efficiency than\nstandard Transformers: for a fixed token budget, similarly sized models\noutperform their dot-product counterparts on tasks involving mathematics,\ncoding, reasoning, and logic. We quantify these gains by demonstrating that\n2-simplicial attention changes the exponent in the scaling laws for knowledge\nand reasoning tasks compared to dot product attention.",
      "upvotes": 2,
      "discussionId": "686732e19db35afc9c304cd1"
    },
    "publishedAt": "2025-07-03T12:16:34.000Z",
    "title": "Fast and Simplex: 2-Simplicial Attention in Triton",
    "summary": "Recent work has shown that training loss scales as a power law with both\nmodel size and the number of tokens, and that achieving compute-optimal models\nrequires scaling model size and token count together. However, these scaling\nlaws assume an infinite supply of data and apply primarily in compute-bound\nsettings. As modern large language models increasingly rely on massive\ninternet-scale datasets, the assumption that they are compute-bound is becoming\nless valid. This shift highlights the need for architectures that prioritize\ntoken efficiency.\n  In this work, we investigate the use of the 2-simplicial Transformer, an\narchitecture that generalizes standard dot-product attention to trilinear\nfunctions through an efficient Triton kernel implementation. We demonstrate\nthat the 2-simplicial Transformer achieves better token efficiency than\nstandard Transformers: for a fixed token budget, similarly sized models\noutperform their dot-product counterparts on tasks involving mathematics,\ncoding, reasoning, and logic. We quantify these gains by demonstrating that\n2-simplicial attention changes the exponent in the scaling laws for knowledge\nand reasoning tasks compared to dot product attention.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.02754.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "651e96991b97c9f33d26bde6",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
      "fullname": "Elie Bakouch",
      "name": "eliebak",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 179
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2507.02726",
      "authors": [
        {
          "_id": "68673e349db35afc9c304d02",
          "name": "Matthieu Zimmer",
          "hidden": false
        },
        {
          "_id": "68673e349db35afc9c304d03",
          "name": "Xiaotong Ji",
          "hidden": false
        },
        {
          "_id": "68673e349db35afc9c304d04",
          "name": "Rasul Tutunov",
          "hidden": false
        },
        {
          "_id": "68673e349db35afc9c304d05",
          "name": "Anthony Bordg",
          "hidden": false
        },
        {
          "_id": "68673e349db35afc9c304d06",
          "name": "Jun Wang",
          "hidden": false
        },
        {
          "_id": "68673e349db35afc9c304d07",
          "name": "Haitham Bou Ammar",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/631c375768f7da9ad2496bf6/j0vqZ_s8kw-ALYV8UCDlF.png"
      ],
      "publishedAt": "2025-07-03T15:41:38.000Z",
      "submittedOnDailyAt": "2025-07-04T01:09:09.946Z",
      "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving",
      "submittedOnDailyBy": {
        "_id": "631c375768f7da9ad2496bf6",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631c375768f7da9ad2496bf6/1sDOoecA6e1v_hn_VAgUq.jpeg",
        "isPro": true,
        "fullname": "Haitham Bou Ammar",
        "user": "hba123",
        "type": "user"
      },
      "summary": "Reasoning remains a challenging task for large language models (LLMs),\nespecially within the logically constrained environment of automated theorem\nproving (ATP), due to sparse rewards and the vast scale of proofs. These\nchallenges are amplified in benchmarks like PutnamBench, which contains\nuniversity-level problems requiring complex, multi-step reasoning. To address\nthis, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new\nframework in which agents generate and pursue their subgoals based on the\nevolving proof state. Given this more structured generation of goals, the\nresulting problem becomes more amenable to search. We then apply Monte Carlo\nTree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our\napproach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs\nfor subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B)\nsolves 26 problems, achieving new state-of-the-art results with models at this\nscale.",
      "upvotes": 1,
      "discussionId": "68673e359db35afc9c304d08"
    },
    "publishedAt": "2025-07-03T11:41:38.000Z",
    "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving",
    "summary": "Reasoning remains a challenging task for large language models (LLMs),\nespecially within the logically constrained environment of automated theorem\nproving (ATP), due to sparse rewards and the vast scale of proofs. These\nchallenges are amplified in benchmarks like PutnamBench, which contains\nuniversity-level problems requiring complex, multi-step reasoning. To address\nthis, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new\nframework in which agents generate and pursue their subgoals based on the\nevolving proof state. Given this more structured generation of goals, the\nresulting problem becomes more amenable to search. We then apply Monte Carlo\nTree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our\napproach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs\nfor subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B)\nsolves 26 problems, achieving new state-of-the-art results with models at this\nscale.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/631c375768f7da9ad2496bf6/j0vqZ_s8kw-ALYV8UCDlF.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.02726.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "631c375768f7da9ad2496bf6",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631c375768f7da9ad2496bf6/1sDOoecA6e1v_hn_VAgUq.jpeg",
      "fullname": "Haitham Bou Ammar",
      "name": "hba123",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 18
    },
    "isAuthorParticipating": false
  }
]